# הנחיות פיתוח למאנוס AI - ממשק ניהול מרפאת שיניים

## תוכנית ביצוע ובדיקות אגרסיביות עבור Manus.im

בהתבסס על הארכיטקטורה המפורטת, עקרונות העיצוב, והצורך בפלטפורמה סקיילבילית, הכנתי סט הנחיות מפורט, שלב אחר שלב, לביצוע הפרויקט עבור manus.im.

התוכנית בנויה באופן מודולרי כדי להתמודד עם מגבלות זיכרון והקשר, ומדגישה פרוטוקול בדיקות אגרסיבי ומתמשך המבוסס על כלי קוד פתוח, כפי שביקשת.

## 1. פילוסופיית ליבה ועקרונות מנחים

הפרויקט יתבסס על שלושה עקרונות יסוד כדי להבטיח יציבות, סקיילביליות ואמינות:

### פיתוח מודולרי (Modular Development)
כל רכיב במערכת (כל סוכן AI, כל מודול UI) יפותח וייבדק כיחידה עצמאית לפני אינטגרציה. גישה זו מפחיתה את מורכבות ההקשר בכל שלב ומקלה על איתור באגים.

### פיתוח מונחה-בדיקות (Test-Driven Development - TDD)
עבור כל תכונה, ייכתבו תחילה בדיקות המגדירות את ההתנהגות הרצויה. הקוד ייכתב לאחר מכן במטרה לעבור את הבדיקות הללו.

### הערכה מתמשכת (Continuous Evaluation)
בדיקות המערכת, ובמיוחד הערכת ביצועי סוכני ה-AI, לא יהיו אירוע חד-פעמי. הן ישולבו בתהליך ה-CI/CD וירוצו באופן אוטומטי ותדיר כדי לזהות רגרסיות וכשלים באופן מיידי.

## 2. תוכנית ביצוע מודולרית - שלב אחר שלב

הפיתוח יתבצע בשלבים מוגדרים, כאשר כל שלב מספק ערך מדיד ונבנה על קודמו.

### שלב 0: הקמת יסודות ותשתית בדיקות (שבוע 1-2)

**מטרה:** להכין סביבת פיתוח ובדיקות אוטומטית, יציבה וניתנת לשחזור.

#### הקמת בקרת גרסאות:
- **פעולה:** יצירת מאגר Git מרכזי
- **הנחיה:** הגדרת מדיניות ענפים (Branching Policy) ברורה (למשל, GitFlow) להפרדה בין פיתוח, בדיקות ופרודקשן

#### הגדרת תשתית כקוד (Infrastructure as Code - IaC):
- **פעולה:** כתיבת סקריפטים של Terraform או AWS CDK להקמת כל רכיבי התשתית ב-AWS (VPC, EC2, RDS, Fargate, IAM Roles)
- **הנחיה:** התשתית תוגדר עם הפרדת רשתות קפדנית (Private/Public Subnets) ותאימות HIPAA מהיום הראשון (הצפנה, בקרת גישה מינימלית)

#### בניית צינור CI/CD (Continuous Integration/Continuous Deployment):
- **פעולה:** הקמת תהליך אוטומטי באמצעות GitHub Actions
- **הנחיה:** הצינור יוגדר כך שכל push לענף הפיתוח יפעיל אוטומטית:
  - בדיקות יחידה (Unit Tests)
  - בדיקות איכות קוד (Linters)
  - בניית קונטיינרים של Docker ודחיפתם למאגר (ECR)
  - פריסה אוטומטית לסביבת Staging ייעודית

### שלב 1: MVP - סוכן טקסט וליבת ממשק הניהול (שבוע 3-8)

**מטרה:** אימות הלוגיקה העסקית המרכזית ויצירת מוצר בר-קיימא ראשוני.

#### מודול 1.1: הקמת מאגר הידע (agent_kb):
- **פעולה:** יצירת מבנה הספריות הפיזי (core_docs, knowledge_cards) וניהולו תחת Git
- **הנחיה:** כתיבת גרסאות ראשוניות של מסמכי הליבה (persona, tool_specifications) ויצירת קבצי YAML לדוגמה עבור לוחות זמנים ושירותים

#### מודול 1.2: פיתוח סוכני הליבה (CrewAI):
- **פעולה:** פיתוח הסוכנים: ReceptionistAgent, SchedulerAgent, ו-KnowledgeBaseManager
- **הנחיה:** פיתוח הכלי המרכזי DentalPMS Tool כשכבת הפשטה (Abstraction Layer) מעל ה-API של Open Dental, תוך מימוש "מנוע הזמינות"

#### מודול 1.3: פיתוח ממשק ניהול בסיסי (React + Ant Design):
- **פעולה:** בניית המודולים הקריטיים ל-MVP: "היסטוריית שיחות ובקרה" (כולל ממשק הצ'אט להתערבות) ו"ניהול צוות וידע" (בגרסה ראשונית המאפשרת עריכת קבצי YAML)
- **הנחיה:** הממשק יפותח תוך שימוש ברכיבים מודולריים כדי לאפשר הרחבה עתידית קלה

#### פרוטוקול בדיקות אגרסיבי - שלב 1:
- **בדיקות יחידה (Jest):** כיסוי של 100% ללוגיקה ב-DentalPMS Tool ולפונקציות שירות בממשק
- **בדיקות רכיבים (React Testing Library):** בדיקה של כל רכיב UI בנפרד, כולל אינטראקציות משתמש בסיסיות
- **בדיקות E2E (Playwright):** יצירת 5-10 תרחישי משתמש מרכזיים המדמים שיחת WhatsApp מלאה, כולל התערבות אנושית דרך ממשק הצ'אט

#### הערכת סוכנים (DeepEval):
- יצירת "סט נתונים מוזהב" (Golden Dataset) של 50 שיחות לדוגמה עם תוצאות צפויות
- הרצה אוטומטית של בדיקות Answer Relevancy, Faithfulness, ו-Task Completion מול סט הנתונים הזה בכל build

## 3. פרוטוקול בדיקות אגרסיבי ומתמשך

זהו לב ליבה של הבטחת האיכות. הוא יפעל במקביל לכל שלבי הפיתוח.

### 3.1. ארגז הכלים (קוד פתוח):

#### בדיקות UI (פונקציונליות ו-E2E): Playwright
נבחר בזכות יכולותיו החזקות להרצת בדיקות חוצות-דפדפנים, הקלטת תרחישים, והמתנה אוטומטית לאלמנטים (Auto-wait), המפחיתה "Flaky tests".

#### בדיקות יחידה ורכיבים (JS): Jest בשילוב עם React Testing Library
הסטנדרט בתעשייה לבדיקות React, עם יכולות Snapshot ו-Mocking מובנות.

#### בדיקות עומס (API): Locust
נבחר בזכות היכולת להגדיר התנהגות משתמשים מורכבת בקוד Python פשוט, והתאמתו הגבוהה לבדיקת שירותי FastAPI.

#### הערכת סוכני LLM: DeepEval
נבחר בזכות האינטגרציה הפשוטה עם Pytest, מגוון המדדים המובנים (RAG, שיחה, שימוש בכלים), והיכולת להגדיר מדדים מותאמים אישית.

### 3.2. תזמון וקצב הבדיקות (Cadence):

הבדיקות ירוצו בתדירויות שונות כדי לאזן בין מהירות משוב לכיסוי מעמיק:

#### בעת כל Commit לענף פיתוח:
- **מה ירוץ:** כל בדיקות היחידה, בדיקות הרכיבים, ובדיקות איכות קוד (Linters)
- **מטרה:** משוב מיידי למפתח (פחות מ-2 דקות)

#### בעת פתיחת Pull Request לענף הראשי (main):
- **מה ירוץ:** כל הבדיקות מהשלב הקודם + סוויטת בדיקות E2E מצומצמת ("Smoke Tests") + סוויטת הערכת סוכנים בסיסית על 20 מקרים
- **מטרה:** לוודא שהשינוי אינו שובר פונקציונליות קריטית לפני המיזוג

#### ריצה לילית (Nightly Build) על ענף הראשי:
- **מה ירוץ:** כל הבדיקות, כולל:
  - סוויטת ה-E2E המלאה של Playwright
  - הערכת סוכנים מלאה (DeepEval) על כל "סט הנתונים המוזהב"
  - בדיקת עומס בסיסית (Locust) עם 50 משתמשים וירטואליים למשך 10 דקות
- **מטרה:** זיהוי רגרסיות, ירידה בביצועי הסוכנים, ובעיות ביצועים ראשוניות

#### ריצה שבועית (בסביבת Staging):
- **מה ירוץ:** בדיקת עומס אגרסיבית (Locust) המדמה מאות משתמשים בו-זמנית למשך שעה
- **מטרה:** זיהוי דליפות זיכרון, צווארי בקבוק במסד הנתונים, והתנהגות המערכת תחת לחץ מתמשך

### 3.3. פירוט סוגי הבדיקות:

#### בדיקות סימולציה (Playwright & DeepEval):
**הנחיה:** יצירת קבצי בדיקה המגדירים תרחישי שיחה מורכבים מקצה לקצה. לדוגמה: "משתמש מבקש תור, הסוכן לא מוצא, המשתמש משנה את הבקשה, הסוכן מציע 3 אופציות, המשתמש בוחר, הסוכן מאשר". כל תרחיש כזה הוא קובץ בדיקה.

#### בדיקות עומס (Locust):
**הנחיה:** יצירת קובץ locustfile.py המגדיר "התנהגות משתמש" הכוללת שליחת הודעות, המתנה לתגובה, ושליחת הודעות המשך. Locust יריץ מאות "משתמשים" כאלה במקביל נגד ה-API של FastAPI.

#### בדיקות קליקים (Playwright):
**הנחיה:** שימוש ב-Playwright Recorder כדי להקליט אינטראקציות של משתמש בממשק הניהול (למשל, סינון שיחות, פתיחת תמלול, השתלטות על שיחה) ולהפוך אותן לבדיקות אוטומטיות שרצות מחדש בכל build.

#### בדיקות מדמות משתמש (User Simulation):
**הנחיה:** זהו שילוב של כל הכלים. תרחיש E2E ב-Playwright יפעיל שיחה, ובמקביל, סקריפט בדיקה יאמת באמצעות DeepEval שהתשובות של הסוכן עומדות במדדי האיכות שהוגדרו, ויבדוק בלוגים של המערכת לוודא שהאינטראקציות עם Open Dental API התבצעו כצפוי.

## סיכום

על ידי אימוץ תוכנית מודולרית זו ופרוטוקול בדיקות אגרסיבי, manus.im תוכל להתמודד עם המורכבות של מערכת סוכנים, להבטיח אמינות גבוהה, ולספק בסיס יציב להוספת יכולות וסוכנים חדשים בעתיד.

---

**תאריך יצירה:** ספטמבר 26, 2025  
**גרסה:** 1.0  
**מיועד עבור:** Manus AI Development Team
